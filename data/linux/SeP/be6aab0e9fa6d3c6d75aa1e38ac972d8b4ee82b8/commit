commit be6aab0e9fa6d3c6d75aa1e38ac972d8b4ee82b8
Author: Eric Sandeen <sandeen@redhat.com>
Commit: Linus Torvalds <torvalds@woody.osdl.org>

    [PATCH] fix memory corruption from misinterpreted bad_inode_ops return values
    
    CVE-2006-5753 is for a case where an inode can be marked bad, switching
    the ops to bad_inode_ops, which are all connected as:
    
    static int return_EIO(void)
    {
            return -EIO;
    }
    
    #define EIO_ERROR ((void *) (return_EIO))
    
    static struct inode_operations bad_inode_ops =
    {
            .create         = bad_inode_create
    ...etc...
    
    The problem here is that the void cast causes return types to not be
    promoted, and for ops such as listxattr which expect more than 32 bits of
    return value, the 32-bit -EIO is interpreted as a large positive 64-bit
    number, i.e. 0x00000000fffffffa instead of 0xfffffffa.
    
    This goes particularly badly when the return value is taken as a number of
    bytes to copy into, say, a user's buffer for example...
    
    I originally had coded up the fix by creating a return_EIO_<TYPE> macro
    for each return type, like this:
    
    static int return_EIO_int(void)
    {
            return -EIO;
    }
    #define EIO_ERROR_INT ((void *) (return_EIO_int))
    
    static struct inode_operations bad_inode_ops =
    {
            .create         = EIO_ERROR_INT,
    ...etc...
    
    but Al felt that it was probably better to create an EIO-returner for each
    actual op signature.  Since so few ops share a signature, I just went ahead
    & created an EIO function for each individual file & inode op that returns
    a value.
    
    Signed-off-by: Eric Sandeen <sandeen@redhat.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Andrew Morton <akpm@osdl.org>
    Signed-off-by: Linus Torvalds <torvalds@osdl.org>
